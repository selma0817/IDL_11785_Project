{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calflops import calculate_flops\n",
    "from torchvision import models\n",
    "import json\n",
    "import torch\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(\"Device: \", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load models\n",
    "models = [('placeholder'), models.alexnet()]\n",
    "\n",
    "metrics = {\n",
    "    \"Placeholder1\": {\"FLOPs\": 4.1e9, \"params\": 23e6, \"MACs\": 2.5e9},\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FLOPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE = (3, 244, 244)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over all models\n",
    "for model_name, model in models:\n",
    "    batch_size = 1\n",
    "    input_shape = (batch_size, INPUT_SIZE)\n",
    "    flops, macs, params = calculate_flops(model=model, \n",
    "                                        input_shape=input_shape,\n",
    "                                        output_as_string=True,\n",
    "                                        output_precision=4)\n",
    "    metrics[model_name] = {\n",
    "        \"FLOPs\": flops, \n",
    "        \"params\": macs, \n",
    "        \"MACs\": params\n",
    "    }\n",
    "    print(\"Model: %s, FLOPs:%s   MACs:%s   Params:%s \\n\" %(model_name, flops, macs, params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define test_loader\n",
    "test_loader = None\n",
    "# define loss function\n",
    "criterion = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader):\n",
    "    model.eval() # set model in evaluation mode\n",
    "    tloss, tacc = 0, 0 # Monitoring loss and accuracy\n",
    "    batch_bar   = tqdm(total=len(test_loader), dynamic_ncols=True, position=0, leave=False, desc='Val')\n",
    "\n",
    "    for i, (datapoints, labels) in enumerate(test_loader):\n",
    "\n",
    "        ### Move data to device (ideally GPU)\n",
    "        datapoints      = datapoints.to(device)\n",
    "        labels    = labels.to(device)\n",
    "\n",
    "        # makes sure that there are no gradients computed as we are not training the model now\n",
    "        with torch.inference_mode():\n",
    "            ### Forward Propagation\n",
    "            logits  = model(datapoints)\n",
    "            ### Loss Calculation\n",
    "            loss    = criterion(logits, labels)\n",
    "\n",
    "        tloss   += loss.item()\n",
    "        tacc    += torch.sum(torch.argmax(logits, dim= 1) == labels).item()/logits.shape[0]\n",
    "\n",
    "        # Do you think we need loss.backward() and optimizer.step() here?\n",
    "\n",
    "        batch_bar.set_postfix(loss=\"{:.04f}\".format(float(vloss / (i + 1))),\n",
    "                              acc=\"{:.04f}%\".format(float(vacc*100 / (i + 1))))\n",
    "        batch_bar.update()\n",
    "\n",
    "        ### Release memory\n",
    "        del datapoints, labels, logits\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    batch_bar.close()\n",
    "    tloss   /= len(test_loader)\n",
    "    tacc    /= len(test_loader)\n",
    "\n",
    "    return tloss, tacc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name, model in models:\n",
    "    loss, acc = test(model=model, test_loader=test_loader)\n",
    "    metrics[model_name] = {\n",
    "        \"loss\": loss, \n",
    "        \"acc\": acc, \n",
    "    }\n",
    "    print(\"Model: %s, Loss: %s, Acc: %s \\n\" %(model_name, loss, acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(metrics, orient=\"index\")\n",
    "df.reset_index(inplace=True)\n",
    "df.rename(columns={\"index\": \"model_name\"}, inplace=True)\n",
    "\n",
    "print(df)\n",
    "\n",
    "# save to csv file\n",
    "df.to_csv(\"IDL_11785_Project/metrics/metrics_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(data=df, x=\"name\", y=\"FLOPs\")\n",
    "plt.title(\"Comparison of FLOPs Across Models\")\n",
    "plt.xlabel(\"Model\")\n",
    "plt.ylabel(\"FLOPs\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "plt.savefig(\"IDL_11785_Project/metrics/plots/FLOPs_comparison.png\", dpi=300, transparent=True, bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
