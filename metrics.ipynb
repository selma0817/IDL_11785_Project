{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  cuda\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import yaml\n",
    "from networks import HRNet_w32_256x192\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(\"Device: \", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cocoapi\t\t\t    dataloader.py  models\tREADME.md\n",
      "cuda-keyring_1.1-1_all.deb  metrics\t   networks.py\tscripts\n",
      "data\t\t\t    metrics.ipynb  __pycache__\ttrainer.py\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'AUTO_RESUME': True, 'CUDNN': {'BENCHMARK': True, 'DETERMINISTIC': False, 'ENABLED': True}, 'DATA_DIR': '', 'GPUS': '(0,1,2,3)', 'OUTPUT_DIR': 'output', 'LOG_DIR': 'log', 'WORKERS': 24, 'PRINT_FREQ': 100, 'DATASET': {'COLOR_RGB': True, 'DATASET': 'coco', 'DATA_FORMAT': 'jpg', 'FLIP': True, 'NUM_JOINTS_HALF_BODY': 8, 'PROB_HALF_BODY': 0.3, 'ROOT': 'data/coco/', 'ROT_FACTOR': 45, 'SCALE_FACTOR': 0.35, 'TEST_SET': 'val2017', 'TRAIN_SET': 'train2017'}, 'MODEL': {'INIT_WEIGHTS': True, 'NAME': 'pose_hrnet', 'NUM_JOINTS': 17, 'PRETRAINED': 'models/HRNet/paths/pose_hrnet_w32_256x192.pth', 'TARGET_TYPE': 'gaussian', 'IMAGE_SIZE': [192, 256], 'HEATMAP_SIZE': [48, 64], 'SIGMA': 2, 'EXTRA': {'PRETRAINED_LAYERS': ['conv1', 'bn1', 'conv2', 'bn2', 'layer1', 'transition1', 'stage2', 'transition2', 'stage3', 'transition3', 'stage4'], 'FINAL_CONV_KERNEL': 1, 'STAGE2': {'NUM_MODULES': 1, 'NUM_BRANCHES': 2, 'BLOCK': 'BASIC', 'NUM_BLOCKS': [4, 4], 'NUM_CHANNELS': [32, 64], 'FUSE_METHOD': 'SUM'}, 'STAGE3': {'NUM_MODULES': 4, 'NUM_BRANCHES': 3, 'BLOCK': 'BASIC', 'NUM_BLOCKS': [4, 4, 4], 'NUM_CHANNELS': [32, 64, 128], 'FUSE_METHOD': 'SUM'}, 'STAGE4': {'NUM_MODULES': 3, 'NUM_BRANCHES': 4, 'BLOCK': 'BASIC', 'NUM_BLOCKS': [4, 4, 4, 4], 'NUM_CHANNELS': [32, 64, 128, 256], 'FUSE_METHOD': 'SUM'}}}, 'LOSS': {'USE_TARGET_WEIGHT': True}, 'TRAIN': {'BATCH_SIZE_PER_GPU': 32, 'SHUFFLE': True, 'BEGIN_EPOCH': 0, 'END_EPOCH': 210, 'OPTIMIZER': 'adam', 'LR': 0.001, 'LR_FACTOR': 0.1, 'LR_STEP': [170, 200], 'WD': 0.0001, 'GAMMA1': 0.99, 'GAMMA2': 0.0, 'MOMENTUM': 0.9, 'NESTEROV': False}, 'TEST': {'BATCH_SIZE_PER_GPU': 32, 'COCO_BBOX_FILE': 'data/coco/person_detection_results/COCO_val2017_detections_AP_H_56_person.json', 'BBOX_THRE': 1.0, 'IMAGE_THRE': 0.0, 'IN_VIS_THRE': 0.2, 'MODEL_FILE': '', 'NMS_THRE': 1.0, 'OKS_THRE': 0.9, 'USE_GT_BBOX': True, 'FLIP_TEST': True, 'POST_PROCESS': True, 'SHIFT_HEATMAP': True}, 'DEBUG': {'DEBUG': True, 'SAVE_BATCH_IMAGES_GT': True, 'SAVE_BATCH_IMAGES_PRED': True, 'SAVE_HEATMAPS_GT': True, 'SAVE_HEATMAPS_PRED': True}}\n"
     ]
    }
   ],
   "source": [
    "with open('models/HRNet/configs/w32_256x192_adam_lr1e-3.yaml', \"r\") as file:\n",
    "    config = yaml.safe_load(file)\n",
    "    print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extra = config['MODEL']['EXTRA']\n",
    "extra['FINAL_CONV_KERNEL']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test load HRNet\n",
    "HRNet = HRNet_w32_256x192()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load models\n",
    "models = [('placeholder'), models.alexnet()]\n",
    "\n",
    "metrics = {\n",
    "    \"Placeholder1\": {\"FLOPs\": 4.1e9, \"params\": 23e6, \"MACs\": 2.5e9},\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FLOPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE = (3, 244, 244)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over all models\n",
    "for model_name, model in models:\n",
    "    batch_size = 1\n",
    "    input_shape = (batch_size, INPUT_SIZE)\n",
    "    flops, macs, params = calculate_flops(model=model, \n",
    "                                        input_shape=input_shape,\n",
    "                                        output_as_string=True,\n",
    "                                        output_precision=4)\n",
    "    metrics[model_name] = {\n",
    "        \"FLOPs\": flops, \n",
    "        \"params\": macs, \n",
    "        \"MACs\": params\n",
    "    }\n",
    "    print(\"Model: %s, FLOPs:%s   MACs:%s   Params:%s \\n\" %(model_name, flops, macs, params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define test_loader\n",
    "test_loader = None\n",
    "# define loss function\n",
    "criterion = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader):\n",
    "    model.eval() # set model in evaluation mode\n",
    "    tloss, tacc = 0, 0 # Monitoring loss and accuracy\n",
    "    batch_bar   = tqdm(total=len(test_loader), dynamic_ncols=True, position=0, leave=False, desc='Val')\n",
    "\n",
    "    for i, (datapoints, labels) in enumerate(test_loader):\n",
    "\n",
    "        ### Move data to device (ideally GPU)\n",
    "        datapoints      = datapoints.to(device)\n",
    "        labels    = labels.to(device)\n",
    "\n",
    "        # makes sure that there are no gradients computed as we are not training the model now\n",
    "        with torch.inference_mode():\n",
    "            ### Forward Propagation\n",
    "            logits  = model(datapoints)\n",
    "            ### Loss Calculation\n",
    "            loss    = criterion(logits, labels)\n",
    "\n",
    "        tloss   += loss.item()\n",
    "        tacc    += torch.sum(torch.argmax(logits, dim= 1) == labels).item()/logits.shape[0]\n",
    "\n",
    "        # Do you think we need loss.backward() and optimizer.step() here?\n",
    "\n",
    "        batch_bar.set_postfix(loss=\"{:.04f}\".format(float(vloss / (i + 1))),\n",
    "                              acc=\"{:.04f}%\".format(float(vacc*100 / (i + 1))))\n",
    "        batch_bar.update()\n",
    "\n",
    "        ### Release memory\n",
    "        del datapoints, labels, logits\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    batch_bar.close()\n",
    "    tloss   /= len(test_loader)\n",
    "    tacc    /= len(test_loader)\n",
    "\n",
    "    return tloss, tacc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name, model in models:\n",
    "    loss, acc = test(model=model, test_loader=test_loader)\n",
    "    metrics[model_name] = {\n",
    "        \"loss\": loss, \n",
    "        \"acc\": acc, \n",
    "    }\n",
    "    print(\"Model: %s, Loss: %s, Acc: %s \\n\" %(model_name, loss, acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(metrics, orient=\"index\")\n",
    "df.reset_index(inplace=True)\n",
    "df.rename(columns={\"index\": \"model_name\"}, inplace=True)\n",
    "\n",
    "print(df)\n",
    "\n",
    "# save to csv file\n",
    "df.to_csv(\"IDL_11785_Project/metrics/metrics_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(data=df, x=\"name\", y=\"FLOPs\")\n",
    "plt.title(\"Comparison of FLOPs Across Models\")\n",
    "plt.xlabel(\"Model\")\n",
    "plt.ylabel(\"FLOPs\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "plt.savefig(\"IDL_11785_Project/metrics/plots/FLOPs_comparison.png\", dpi=300, transparent=True, bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
