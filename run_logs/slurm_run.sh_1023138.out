project run
Mon Dec  2 18:59:16 2024       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA A100-PCIE-40GB          On  |   00000000:85:00.0 Off |                    0 |
| N/A   28C    P0             35W /  250W |       0MiB /  40960MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
srun
cuda
=> set stage2.cls_token wd to 0
Transform = 
Resize(size=256, interpolation=bicubic, max_size=None, antialias=True)
CenterCrop(size=(224, 224))
ToTensor()
Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))
---------------------------
reading from datapath /ix1/hkarim/yip33/kaggle_dataset/image_net100
scale is [0.08, 1.0] <class 'list'>
Transform = 
Resize(size=256, interpolation=bicubic, max_size=None, antialias=True)
CenterCrop(size=(224, 224))
ToTensor()
Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))
---------------------------
reading from datapath /ix1/hkarim/yip33/kaggle_dataset/image_net100
	Train Loss 4.5855	 Learning Rate 0.0000508
	Val Top1 4.5800%	Val Top5 16.8600%	 Val Loss 4.4105
	Train Loss 4.5090	 Learning Rate 0.0001006
	Val Top1 10.0600%	Val Top5 30.7800%	 Val Loss 4.0151
	Train Loss 4.4089	 Learning Rate 0.0001504
	Val Top1 16.0000%	Val Top5 42.4400%	 Val Loss 3.7650
	Train Loss 4.3382	 Learning Rate 0.0002002
	Val Top1 19.8200%	Val Top5 47.7200%	 Val Loss 3.4924
	Train Loss 4.2782	 Learning Rate 0.0002485
	Val Top1 22.4400%	Val Top5 49.5000%	 Val Loss 3.4041
	Train Loss 4.2323	 Learning Rate 0.0002479
	Val Top1 27.9600%	Val Top5 57.8000%	 Val Loss 3.1192
	Train Loss 4.1571	 Learning Rate 0.0002471
	Val Top1 32.6000%	Val Top5 63.9800%	 Val Loss 2.9439
	Train Loss 4.0837	 Learning Rate 0.0002462
	Val Top1 37.0800%	Val Top5 68.2000%	 Val Loss 2.6990
	Train Loss 4.0315	 Learning Rate 0.0002452
	Val Top1 39.6200%	Val Top5 70.2600%	 Val Loss 2.6299
	Train Loss 3.9779	 Learning Rate 0.0002441
	Val Top1 43.0600%	Val Top5 72.3800%	 Val Loss 2.4661
	Train Loss 3.9232	 Learning Rate 0.0002429
	Val Top1 46.9000%	Val Top5 75.7000%	 Val Loss 2.3269
	Train Loss 3.8806	 Learning Rate 0.0002416
	Val Top1 48.0000%	Val Top5 77.4200%	 Val Loss 2.2625
	Train Loss 3.8431	 Learning Rate 0.0002401
	Val Top1 49.3600%	Val Top5 77.7800%	 Val Loss 2.2247
	Train Loss 3.8067	 Learning Rate 0.0002386
	Val Top1 52.9800%	Val Top5 80.8200%	 Val Loss 2.0818
	Train Loss 3.7733	 Learning Rate 0.0002369
	Val Top1 54.5400%	Val Top5 80.7600%	 Val Loss 2.0173
	Train Loss 3.7278	 Learning Rate 0.0002352
	Val Top1 57.5200%	Val Top5 82.5600%	 Val Loss 1.8886
	Train Loss 3.6911	 Learning Rate 0.0002333
	Val Top1 58.7400%	Val Top5 83.9200%	 Val Loss 1.8484
	Train Loss 3.6324	 Learning Rate 0.0002313
	Val Top1 60.6600%	Val Top5 84.8800%	 Val Loss 1.7709
	Train Loss 3.6214	 Learning Rate 0.0002292
	Val Top1 62.0600%	Val Top5 86.1200%	 Val Loss 1.7170
	Train Loss 3.5945	 Learning Rate 0.0002271
	Val Top1 62.4400%	Val Top5 85.7600%	 Val Loss 1.7134
	Train Loss 3.5571	 Learning Rate 0.0002248
	Val Top1 65.0400%	Val Top5 87.2000%	 Val Loss 1.6005
	Train Loss 3.5271	 Learning Rate 0.0002225
	Val Top1 65.1400%	Val Top5 87.4800%	 Val Loss 1.5830
	Train Loss 3.5079	 Learning Rate 0.0002200
	Val Top1 66.5400%	Val Top5 88.7000%	 Val Loss 1.5037
	Train Loss 3.4807	 Learning Rate 0.0002175
	Val Top1 67.4400%	Val Top5 89.2800%	 Val Loss 1.4918
	Train Loss 3.4552	 Learning Rate 0.0002149
	Val Top1 67.9200%	Val Top5 89.5800%	 Val Loss 1.4344
	Train Loss 3.4294	 Learning Rate 0.0002121
	Val Top1 68.6000%	Val Top5 89.8000%	 Val Loss 1.3923
	Train Loss 3.3993	 Learning Rate 0.0002094
	Val Top1 69.9400%	Val Top5 90.6200%	 Val Loss 1.3912
	Train Loss 3.4081	 Learning Rate 0.0002065
	Val Top1 70.4200%	Val Top5 90.9000%	 Val Loss 1.3697
	Train Loss 3.3652	 Learning Rate 0.0002035
	Val Top1 71.1000%	Val Top5 91.3800%	 Val Loss 1.3105
	Train Loss 3.3486	 Learning Rate 0.0002005
	Val Top1 71.4800%	Val Top5 91.7000%	 Val Loss 1.3344
